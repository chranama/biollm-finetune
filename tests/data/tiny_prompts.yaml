model:
  path: "sshleifer/tiny-gpt2"
  load_4bit: false
  load_8bit: false
  bf16: false
  max_length: 256
inference:
  batch_size: 1
  max_input_length: 256
  max_new_tokens: 16
  do_sample: false
  num_beams: 1
data:
  include_snippets: true